import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate


def initialize_session_state():
    if 'responses' not in st.session_state:
        st.session_state['responses'] = []


def get_openai_api_key():
    with st.sidebar:
        openai_api_key = st.text_input(
            "OpenAI API Key", key="chatbot_api_key", type="password")
        st.markdown(
            "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)")
    return openai_api_key


def create_llm(api_key, temperature=0):
    try:
        return ChatOpenAI(model_name="gpt-4o-mini", temperature=temperature, openai_api_key=api_key)
    except Exception as e:
        st.error(f"Error creating LLM: {str(e)}")
        return None


def create_translation_chain(llm):
    prompt = PromptTemplate.from_template(
        """
ì „ë¬¸ ê³µë¬¸ ì²¨ì‚­ ì „ë¬¸ê°€ë¡œì„œ, ëŒ€í•œë¯¼êµ­ì˜ ê³ ìœ„ ê³µë¬´ì›ì´ ë¶€í•˜ ì§ì›ì´ ì‘ì„±í•œ ê³µë¬¸ì„ êµì •í•˜ê³  êµì—´í•˜ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.

ì§€ì¹¨:
- ëª…í™•í•œ ì „ë‹¬: ê³µë¬¸ì˜ ëª©ì ê³¼ ë‚´ìš©ì„ ëª…í™•í•˜ê²Œ ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ ë¬¸ì¥ì„ ë‹¤ë“¬ì–´ ì£¼ì„¸ìš”.
- ì–´ë¬¸ê·œë²” ì¤€ìˆ˜: ì–´ë¬¸ê·œë²”ì— ë§ê²Œ í•œê¸€ë¡œ ì‘ì„±í•˜ë˜, ëœ»ì„ ì •í™•í•˜ê²Œ ì „ë‹¬í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ê²½ìš° ê´„í˜¸ ì•ˆì— í•œìë‚˜ ì™¸êµ­ì–´ë¥¼ í•¨ê»˜ ì ì–´ ì£¼ì„¸ìš”.
- ê°„ê²°í•˜ê³  ëª…í™•í•œ í‘œí˜„: ë¬¸ì„œì˜ ë‚´ìš©ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í‘œí˜„í•˜ë©°, ì¼ë°˜í™”ë˜ì§€ ì•Šì€ ì•½ì–´ì™€ ì „ë¬¸ìš©ì–´ì˜ ì‚¬ìš©ì„ í”¼í•˜ì—¬ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
- ì¶”ê°€ ì •ë³´ ì œê³µ: í•„ìš”í•œ ê²½ìš°, ë…ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì¶”ê°€ì ì¸ ì •ë³´ë‚˜ ì„¤ëª…ì„ ë§ë¶™ì—¬ ì£¼ì„¸ìš”.
- í•­ëª© êµ¬ë¶„: ë¬¸ì„œ ë‚´ìš© êµ¬ë¶„ í•„ìš”ì‹œ ìƒìœ„ í•­ëª©ë¶€í„° í•˜ìœ„ í•­ëª©ê¹Œì§€ 1., ê°€., 1), ê°€), (1), (ê°€), â‘ , ã‰®ì˜ í˜•íƒœë¡œ í‘œì‹œí•©ë‹ˆë‹¤. í•„ìš” ì‹œ â–¡, â—‹, -, ã† ë“±ì˜ íŠ¹ìˆ˜ ê¸°í˜¸ë¡œ í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ê¸ˆì•¡ í‘œê¸°: ê¸ˆì•¡ì€ (ì˜ˆì‹œ: ê¸ˆ113,560ì›(ê¸ˆì¼ì‹­ì¼ë§Œì‚¼ì²œì˜¤ë°±ìœ¡ì‹­ì›)) í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•´ ì£¼ì„¸ìš”.
- ë‚ ì§œ ë° ì‹œê°„ í‘œê¸°: ë‚ ì§œëŠ” YYYY. m. d. í˜•ì‹ìœ¼ë¡œ, ì‹œê°„ì€ HH24:MI í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•´ ì£¼ì„¸ìš”.
- ë¬¸ì„œ ì¢…ë£Œ í‘œì‹œ: ë³¸ë¬¸ì˜ ë‚´ìš©(ë³¸ë¬¸ì— ë¶™ì„ì´ ìˆëŠ” ê²½ìš°ì—ëŠ” ë¶™ì„ì„ ë§í•œë‹¤)ì˜ ë§ˆì§€ë§‰ ê¸€ìì—ì„œ í•œ ê¸€ì ë„ìš°ê³  â€œëâ€ í‘œì‹œë¥¼ í•©ë‹ˆë‹¤.

ì´ ì§€ì¹¨ì„ ë°”íƒ•ìœ¼ë¡œ ê³µë¬¸ì„ ì „ë¬¸ì ì´ê³  íš¨ê³¼ì ì¸ ë¬¸ì„œë¡œ ì™„ì„±í•´ ì£¼ì„¸ìš”. ì²¨ì‚­ í›„, ìˆ˜ì •ëœ ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•˜ì—¬ ì£¼ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤.

ê³µë¬¸ì œëª©: {title}

ê³µë¬¸ë‚´ìš©: {input}
"""
    )
    return prompt | llm


def main():
    st.title("ğŸ’¬ RPA with AI")
    st.caption("ğŸš€ RPA with AI powered by kadragon")
    st.subheader('Official Correction')

    initialize_session_state()
    api_key = get_openai_api_key()

    with st.form('Question'):
        title = st.text_area('ê³µë¬¸ ì œëª©')
        text = st.text_area('ê³µë¬¸ ë‚´ìš©')
        submitted = st.form_submit_button('ë³´ë‚´ê¸°')

    if submitted and api_key:
        llm = create_llm(api_key)
        if llm:
            chain = create_translation_chain(llm)
            with st.spinner('êµì •/êµì—´ ì¤‘...'):
                try:
                    response = chain.invoke({"input": text, "title": title})
                    st.session_state['responses'].append(response.content)
                except Exception as e:
                    st.error(f"êµì •/êµì—´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    for response in st.session_state['responses']:
        st.info(response)


if __name__ == "__main__":
    main()
